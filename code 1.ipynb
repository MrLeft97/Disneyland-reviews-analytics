{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DisneylandReviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['Review_Text', 'Performance']]\n",
    "Paris = df[df['Branch'] == 'Disneyland_Paris']\n",
    "California = df[df['Branch'] == 'Disneyland_California']\n",
    "HongKong = df[df['Branch'] == 'HongKong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = df['Review_Text']\n",
    "content = ' '.join(content_list)\n",
    "tokens = nltk.word_tokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords Removal and only keep text data then change to lowercase\n",
    "mystopwords = stopwords.words('english')\n",
    "words = [w.lower() for w in tokens if w.isalpha() if w.lower()not in mystopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_tags = nltk.pos_tag(tokens) #use unprocessed 'tokens', not 'words'\n",
    "#Generate a list of POS tags\n",
    "POS_tag_list = [(words,tag) for (words,tag) in POS_tags if (tag == 'NNP' and words.isalnum())]\n",
    "#Generate a frequency distribution of all the POS tags\n",
    "tag_freq = nltk.FreqDist(POS_tag_list)\n",
    "#Sort the result \n",
    "sorted_tag_freq = sorted(tag_freq.items(), key = lambda k:k[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Disney', 'NNP'), 14152),\n",
       " (('Disneyland', 'NNP'), 7516),\n",
       " (('Paris', 'NNP'), 5878),\n",
       " (('Florida', 'NNP'), 1909),\n",
       " (('Park', 'NNP'), 1893),\n",
       " (('Mountain', 'NNP'), 1805),\n",
       " (('Mickey', 'NNP'), 1215),\n",
       " (('Studios', 'NNP'), 1050),\n",
       " (('Space', 'NNP'), 1029),\n",
       " (('Christmas', 'NNP'), 977),\n",
       " (('Thunder', 'NNP'), 910),\n",
       " (('World', 'NNP'), 903),\n",
       " (('Hotel', 'NNP'), 867),\n",
       " (('Walt', 'NNP'), 830),\n",
       " (('Orlando', 'NNP'), 819),\n",
       " (('Buzz', 'NNP'), 753),\n",
       " (('Peter', 'NNP'), 697),\n",
       " (('Caribbean', 'NNP'), 685),\n",
       " (('Main', 'NNP'), 623),\n",
       " (('US', 'NNP'), 622),\n",
       " (('Food', 'NNP'), 615),\n",
       " (('Pan', 'NNP'), 614),\n",
       " (('Jones', 'NNP'), 609),\n",
       " (('Indiana', 'NNP'), 600),\n",
       " (('Magic', 'NNP'), 598),\n",
       " (('California', 'NNP'), 593),\n",
       " (('DLP', 'NNP'), 566),\n",
       " (('Fast', 'NNP'), 544),\n",
       " (('Street', 'NNP'), 526),\n",
       " (('Star', 'NNP'), 525),\n",
       " (('France', 'NNP'), 522),\n",
       " (('Village', 'NNP'), 484),\n",
       " (('USA', 'NNP'), 477),\n",
       " (('Lightyear', 'NNP'), 471),\n",
       " (('Just', 'NNP'), 446),\n",
       " (('Dreams', 'NNP'), 442),\n",
       " (('Euro', 'NNP'), 441),\n",
       " (('Pirates', 'NNP'), 421),\n",
       " (('New', 'NNP'), 418),\n",
       " (('Big', 'NNP'), 408),\n",
       " (('Great', 'NNP'), 392),\n",
       " (('Mouse', 'NNP'), 381),\n",
       " (('English', 'NNP'), 375),\n",
       " (('Ratatouille', 'NNP'), 373),\n",
       " (('A', 'NNP'), 364),\n",
       " (('Halloween', 'NNP'), 359),\n",
       " (('Tower', 'NNP'), 355),\n",
       " (('Europe', 'NNP'), 344),\n",
       " (('Studio', 'NNP'), 339),\n",
       " (('Coaster', 'NNP'), 337)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tag_freq[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = California['Review_Text']\n",
    "content = ' '.join(content_list)\n",
    "tokens = nltk.word_tokenize(content)\n",
    "\n",
    "#change all tokens into lower case \n",
    "words1 = [w.lower() for w in tokens]   #list comprehension \n",
    "#only keep text words, no numbers \n",
    "words2 = [w for w in words1 if w.isalpha()]\n",
    "\n",
    "POS_tags = nltk.pos_tag(tokens) #use unprocessed 'tokens', not 'words'\n",
    "#Generate a list of POS tags\n",
    "POS_tag_list = [(words2,tag) for (words2,tag) in POS_tags if (tag == 'NNP' and words2.isalnum())]\n",
    "#Generate a frequency distribution of all the POS tags\n",
    "tag_freq = nltk.FreqDist(POS_tag_list)\n",
    "#Sort the result \n",
    "sorted_tag_freq = sorted(tag_freq.items(), key = lambda k:k[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Disneyland', 'NNP'), 15889),\n",
       " (('Disney', 'NNP'), 12396),\n",
       " (('California', 'NNP'), 4172),\n",
       " (('World', 'NNP'), 3004),\n",
       " (('Mountain', 'NNP'), 2672),\n",
       " (('Adventure', 'NNP'), 2496),\n",
       " (('Park', 'NNP'), 1847),\n",
       " (('Space', 'NNP'), 1430),\n",
       " (('Indiana', 'NNP'), 1356),\n",
       " (('Jones', 'NNP'), 1319),\n",
       " (('Christmas', 'NNP'), 1288),\n",
       " (('Fast', 'NNP'), 1243),\n",
       " (('Florida', 'NNP'), 1171),\n",
       " (('Star', 'NNP'), 1130),\n",
       " (('Mickey', 'NNP'), 1104),\n",
       " (('Walt', 'NNP'), 1093),\n",
       " (('Pass', 'NNP'), 951),\n",
       " (('Halloween', 'NNP'), 905),\n",
       " (('Splash', 'NNP'), 891),\n",
       " (('Magic', 'NNP'), 858),\n",
       " (('Matterhorn', 'NNP'), 840),\n",
       " (('Main', 'NNP'), 811),\n",
       " (('Mansion', 'NNP'), 787),\n",
       " (('Caribbean', 'NNP'), 770),\n",
       " (('Haunted', 'NNP'), 754),\n",
       " (('Anaheim', 'NNP'), 745),\n",
       " (('Orlando', 'NNP'), 719),\n",
       " (('Street', 'NNP'), 714),\n",
       " (('Land', 'NNP'), 668),\n",
       " (('Thunder', 'NNP'), 658),\n",
       " (('Fantasmic', 'NNP'), 651),\n",
       " (('Pirates', 'NNP'), 604),\n",
       " (('Disneyworld', 'NNP'), 604),\n",
       " (('Wars', 'NNP'), 592),\n",
       " (('Tours', 'NNP'), 563),\n",
       " (('Great', 'NNP'), 554),\n",
       " (('New', 'NNP'), 544),\n",
       " (('WDW', 'NNP'), 541),\n",
       " (('Kingdom', 'NNP'), 531),\n",
       " (('Food', 'NNP'), 501),\n",
       " (('Cars', 'NNP'), 488),\n",
       " (('Downtown', 'NNP'), 483),\n",
       " (('CA', 'NNP'), 470),\n",
       " (('DL', 'NNP'), 434),\n",
       " (('Small', 'NNP'), 422),\n",
       " (('Just', 'NNP'), 406),\n",
       " (('FastPass', 'NNP'), 405),\n",
       " (('Peter', 'NNP'), 402),\n",
       " (('Fastpass', 'NNP'), 396),\n",
       " (('Pan', 'NNP'), 375)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tag_freq[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos_neg(data, positive_dict, negative_dict):\n",
    "# count of positive and negative words that appeared in each message\n",
    "# net count which is calculated by positive count subtracting negative count. \n",
    "    poscnt = []\n",
    "    negcnt = []\n",
    "    netcnt = []\n",
    "\n",
    "    for nrow in range(0,len(data)):\n",
    "        text = data[nrow]\n",
    "        \n",
    "        qa = 0\n",
    "        qb = 0\n",
    "\n",
    "        for word in positive_dict :\n",
    "            if (word in text) :\n",
    "                qa = qa + 1\n",
    "\n",
    "        for word in negative_dict :\n",
    "            if (word in text) :\n",
    "                qb = qb + 1\n",
    "\n",
    "        qc = qa - qb\n",
    "\n",
    "        poscnt.append(qa)\n",
    "        negcnt.append(qb)\n",
    "        netcnt.append(qc)\n",
    "\n",
    "    return (poscnt, negcnt, netcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.Review_Text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        if you've ever been to disneyland anywhere you...\n",
       "1        its been a while since d last time we visit hk...\n",
       "2        thanks god it wasn   t too hot or too humid wh...\n",
       "3        hk disneyland is a great compact park. unfortu...\n",
       "4        the location is not in the city, took around 1...\n",
       "                               ...                        \n",
       "42651    i went to disneyland paris in july 03 and thou...\n",
       "42652    2 adults and 1 child of 11 visited disneyland ...\n",
       "42653    my eleven year old daughter and myself went to...\n",
       "42654    this hotel, part of the disneyland paris compl...\n",
       "42655    i went to the disneyparis resort, in 1996, wit...\n",
       "Name: Review_Text, Length: 42656, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "scores = [analyzer.polarity_scores(sentence) for sentence in data]\n",
    "neg_s = [i[\"neg\"] for i in scores]\n",
    "neu_s = [i[\"neu\"] for i in scores]\n",
    "pos_s = [i[\"pos\"] for i in scores]\n",
    "compound_s = [i[\"compound\"] for i in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-96b352fe3a83>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['compound_Vader'] = compound_s\n",
      "<ipython-input-54-96b352fe3a83>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Vader'] = df1['compound_Vader'].apply(lambda x:1 if x >= 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "df1['compound_Vader'] = compound_s\n",
    "df1['Vader'] = df1['compound_Vader'].apply(lambda x:1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Performance</th>\n",
       "      <th>compound_Vader</th>\n",
       "      <th>Vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42651</th>\n",
       "      <td>i went to disneyland paris in july 03 and thou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42652</th>\n",
       "      <td>2 adults and 1 child of 11 visited Disneyland ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42653</th>\n",
       "      <td>My eleven year old daughter and myself went to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42654</th>\n",
       "      <td>This hotel, part of the Disneyland Paris compl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42655</th>\n",
       "      <td>I went to the Disneyparis resort, in 1996, wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42656 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review_Text  Performance  \\\n",
       "0      If you've ever been to Disneyland anywhere you...            1   \n",
       "1      Its been a while since d last time we visit HK...            1   \n",
       "2      Thanks God it wasn   t too hot or too humid wh...            1   \n",
       "3      HK Disneyland is a great compact park. Unfortu...            1   \n",
       "4      the location is not in the city, took around 1...            1   \n",
       "...                                                  ...          ...   \n",
       "42651  i went to disneyland paris in july 03 and thou...            1   \n",
       "42652  2 adults and 1 child of 11 visited Disneyland ...            1   \n",
       "42653  My eleven year old daughter and myself went to...            1   \n",
       "42654  This hotel, part of the Disneyland Paris compl...            1   \n",
       "42655  I went to the Disneyparis resort, in 1996, wit...            1   \n",
       "\n",
       "       compound_Vader  Vader  \n",
       "0              0.7069      1  \n",
       "1              0.9866      1  \n",
       "2              0.9920      1  \n",
       "3              0.8425      1  \n",
       "4              0.2846      1  \n",
       "...               ...    ...  \n",
       "42651          0.9894      1  \n",
       "42652          0.9906      1  \n",
       "42653          0.8402      1  \n",
       "42654          0.9538      1  \n",
       "42655          0.9797      1  \n",
       "\n",
       "[42656 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>5855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1399</td>\n",
       "      <td>32522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0      1\n",
       "Actual                \n",
       "0          2880   5855\n",
       "1          1399  32522"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = pd.crosstab(df1['Performance'], df1['Vader'], rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.33      0.44      8735\n",
      "           1       0.85      0.96      0.90     33921\n",
      "\n",
      "    accuracy                           0.83     42656\n",
      "   macro avg       0.76      0.64      0.67     42656\n",
      "weighted avg       0.81      0.83      0.81     42656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df1['Performance'], df1['Vader']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-6637e293f2a6>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"score_TextBlob\"] = df1[\"Review_Text\"].map(lambda x:TextBlob(x).sentiment.polarity)\n",
      "<ipython-input-61-6637e293f2a6>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['TB'] = df1['score_TextBlob'].apply(lambda x:1 if x >= 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "df1[\"score_TextBlob\"] = df1[\"Review_Text\"].map(lambda x:TextBlob(x).sentiment.polarity)\n",
    "df1['TB'] = df1['score_TextBlob'].apply(lambda x:1 if x >= 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Performance</th>\n",
       "      <th>compound_Vader</th>\n",
       "      <th>Vader</th>\n",
       "      <th>score_TextBlob</th>\n",
       "      <th>TB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42651</th>\n",
       "      <td>i went to disneyland paris in july 03 and thou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42652</th>\n",
       "      <td>2 adults and 1 child of 11 visited Disneyland ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42653</th>\n",
       "      <td>My eleven year old daughter and myself went to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42654</th>\n",
       "      <td>This hotel, part of the Disneyland Paris compl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42655</th>\n",
       "      <td>I went to the Disneyparis resort, in 1996, wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42656 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review_Text  Performance  \\\n",
       "0      If you've ever been to Disneyland anywhere you...            1   \n",
       "1      Its been a while since d last time we visit HK...            1   \n",
       "2      Thanks God it wasn   t too hot or too humid wh...            1   \n",
       "3      HK Disneyland is a great compact park. Unfortu...            1   \n",
       "4      the location is not in the city, took around 1...            1   \n",
       "...                                                  ...          ...   \n",
       "42651  i went to disneyland paris in july 03 and thou...            1   \n",
       "42652  2 adults and 1 child of 11 visited Disneyland ...            1   \n",
       "42653  My eleven year old daughter and myself went to...            1   \n",
       "42654  This hotel, part of the Disneyland Paris compl...            1   \n",
       "42655  I went to the Disneyparis resort, in 1996, wit...            1   \n",
       "\n",
       "       compound_Vader  Vader  score_TextBlob  TB  \n",
       "0              0.7069      1        0.243981   1  \n",
       "1              0.9866      1        0.236131   1  \n",
       "2              0.9920      1        0.160498   1  \n",
       "3              0.8425      1        0.189286   1  \n",
       "4              0.2846      1        0.266667   1  \n",
       "...               ...    ...             ...  ..  \n",
       "42651          0.9894      1        0.252273   1  \n",
       "42652          0.9906      1        0.179250   1  \n",
       "42653          0.8402      1        0.153205   1  \n",
       "42654          0.9538      1        0.265327   1  \n",
       "42655          0.9797      1        0.254881   1  \n",
       "\n",
       "[42656 rows x 6 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2396</td>\n",
       "      <td>6339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1390</td>\n",
       "      <td>32531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0      1\n",
       "Actual                \n",
       "0          2396   6339\n",
       "1          1390  32531"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = pd.crosstab(df1['Performance'], df1['TB'], rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non alphabets\n",
    "remove_non_alphabets = lambda x: re.sub(r'[^a-zA-Z]',' ',x)\n",
    "\n",
    "# tokenn alphabets-only list\n",
    "tokenize = lambda x: word_tokenize(x)\n",
    "\n",
    "# assign ps to a lambda function to run on each line of value\n",
    "ps = PorterStemmer()\n",
    "stem = lambda w: [ ps.stem(x) for x in w ]\n",
    "\n",
    "# assign lemmatizer to a lambda function to run on each line of value\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "leammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : [="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-c07aee46cfc4>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Review_Text'] = df1['Review_Text'].apply(remove_non_alphabets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-c07aee46cfc4>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Review_Text'] = df1['Review_Text'].apply(tokenize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-c07aee46cfc4>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Review_Text'] = df1['Review_Text'].apply(stem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-c07aee46cfc4>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Review_Text'] = df1['Review_Text'].apply(leammtizer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=] : Completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-c07aee46cfc4>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Review_Text'] = df1['Review_Text'].apply(lambda x: ' '.join(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Performance</th>\n",
       "      <th>compound_Vader</th>\n",
       "      <th>Vader</th>\n",
       "      <th>score_TextBlob</th>\n",
       "      <th>TB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you ve ever been to disneyland anywher you ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it been a while sinc d last time we visit HK d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank god it wasn t too hot or too humid when ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK disneyland is a great compact park unfortun...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the locat is not in the citi took around hour ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42651</th>\n",
       "      <td>i went to disneyland pari in juli and thought ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42652</th>\n",
       "      <td>adult and child of visit disneyland pari begin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42653</th>\n",
       "      <td>My eleven year old daughter and myself went to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42654</th>\n",
       "      <td>thi hotel part of the disneyland pari complex ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42655</th>\n",
       "      <td>I went to the disneypari resort in with a smal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42656 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review_Text  Performance  \\\n",
       "0      If you ve ever been to disneyland anywher you ...            1   \n",
       "1      it been a while sinc d last time we visit HK d...            1   \n",
       "2      thank god it wasn t too hot or too humid when ...            1   \n",
       "3      HK disneyland is a great compact park unfortun...            1   \n",
       "4      the locat is not in the citi took around hour ...            1   \n",
       "...                                                  ...          ...   \n",
       "42651  i went to disneyland pari in juli and thought ...            1   \n",
       "42652  adult and child of visit disneyland pari begin...            1   \n",
       "42653  My eleven year old daughter and myself went to...            1   \n",
       "42654  thi hotel part of the disneyland pari complex ...            1   \n",
       "42655  I went to the disneypari resort in with a smal...            1   \n",
       "\n",
       "       compound_Vader  Vader  score_TextBlob  TB  \n",
       "0              0.7069      1        0.243981   1  \n",
       "1              0.9866      1        0.236131   1  \n",
       "2              0.9920      1        0.160498   1  \n",
       "3              0.8425      1        0.189286   1  \n",
       "4              0.2846      1        0.266667   1  \n",
       "...               ...    ...             ...  ..  \n",
       "42651          0.9894      1        0.252273   1  \n",
       "42652          0.9906      1        0.179250   1  \n",
       "42653          0.8402      1        0.153205   1  \n",
       "42654          0.9538      1        0.265327   1  \n",
       "42655          0.9797      1        0.254881   1  \n",
       "\n",
       "[42656 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply all above methods to the column ''\n",
    "print('Processing : [=', end='')\n",
    "df1['Review_Text'] = df1['Review_Text'].apply(remove_non_alphabets)\n",
    "print('=', end='')\n",
    "df1['Review_Text'] = df1['Review_Text'].apply(tokenize)\n",
    "print('=', end='')\n",
    "df1['Review_Text'] = df1['Review_Text'].apply(stem)\n",
    "print('=', end='')\n",
    "df1['Review_Text'] = df1['Review_Text'].apply(leammtizer)\n",
    "print('=', end='')\n",
    "df1['Review_Text'] = df1['Review_Text'].apply(lambda x: ' '.join(x))\n",
    "print('] : Completed', end='')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to 30 percent test data and 70 percent train data\n",
    "# labels can be seen as y, an dependent variable\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(df1['Review_Text'],\n",
    "                                                                        df1[\"Performance\"],\n",
    "                                                                        test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-5fe7cbe57d47>:21: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  feature_vector = np.add(feature_vector, model[word])\n"
     ]
    }
   ],
   "source": [
    "# tokenize documents for word2vec\n",
    "tokenized_train = [nltk.word_tokenize(text)\n",
    "                   for text in train_corpus]\n",
    "tokenized_test = [nltk.word_tokenize(text)\n",
    "                   for text in test_corpus]  \n",
    "\n",
    "# build word2vec model                   \n",
    "wv_model = gensim.models.Word2Vec(tokenized_train,\n",
    "                               size=200,                          #set the size or dimension for the word vectors \n",
    "                               window=60,                        #specify the length of the window of words taken as context\n",
    "                               min_count=10)                   #ignores all words with total frequency lower than 10\n",
    "\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector \n",
    "   \n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "# averaged word vector features from word2vec\n",
    "avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                 model=wv_model,\n",
    "                                                 num_features=200)                   \n",
    "avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
    "                                                model=wv_model,\n",
    "                                                num_features=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that trains the model, performs predictions and evaluates the predictions\n",
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    # evaluate model prediction performance   \n",
    "    '''get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)'''\n",
    "    print(metrics.classification_report(test_labels,predictions))\n",
    "    return predictions, get_metrics(true_labels=test_labels, predicted_labels=predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to evaluate our classification models based on four metrics\n",
    "# This defined function is also useful in other cases. This is comparing test_y and pred_y. \n",
    "# Both contain 1s and 0s.\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    metrics_dict = dict(zip([\"accuracy\", \"precision\", \"recall\", \"f1\"], [None]*4))\n",
    "    #metrics_dict = {i:None for i in [\"accuracy\", \"precision\", \"recall\", \"f1\"]}\n",
    "    for m in metrics_dict.keys():\n",
    "        exec('''metrics_dict['{}'] = np.round(                                                    \n",
    "                        metrics.{}_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        2)'''.format(m, m))\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.41      0.54      2609\n",
      "           1       0.87      0.97      0.92     10188\n",
      "\n",
      "    accuracy                           0.86     12797\n",
      "   macro avg       0.83      0.69      0.73     12797\n",
      "weighted avg       0.85      0.86      0.84     12797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign random forest function to an object\n",
    "rf = RandomForestClassifier(criterion=\"entropy\")\n",
    "\n",
    "# predict and evaluate random forest\n",
    "rf_avgwv_predictions, rf_avgwv_metrics = train_predict_evaluate_model(classifier=rf,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1064</td>\n",
       "      <td>1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>9903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1\n",
       "Actual               \n",
       "0          1064  1545\n",
       "1           285  9903"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(test_labels, rf_avgwv_predictions, rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
